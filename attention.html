<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>【論文紹介 | Attention Is All You Need】走る作曲家のAIカフェ</title>
    <link rel="stylesheet" href="style.css"> 
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1050827580219099"
     crossorigin="anonymous"></script>
</head>
<body>
    <header>
        <h1>走る作曲家のAIカフェ</h1>
        <nav>
            <ul>
                <li><a href="index.html">ホーム</a></li>
                <li><a href="study.html">勉強</a></li>
                <li><a href="music.html">音楽</a></li>
                <li><a href="sports.html">スポーツ</a></li>
            </ul>
        </nav>
    </header>
    <main>
        <section>
            <h2>目次</h2>
            <ul>
                <li><a href="#overview">Overview</a></li>
                <li><a href="#abstract">Abstract</a></li>
            </ul>
        </section>
        <section id="overview">
            <h2>Overview</h2>
            "<a href="https://arxiv.org/pdf/1706.03762">Attention Is All You Need</a>" は、Self-Attentionに基づくTransformerモデルが、従来のRNNやCNNを用いた手法を超える性能を発揮し、翻訳などの自然言語処理タスクにおいて効果的であることを示した論文です。<br>
            このページでは、その内容を順に追っていきます。
        </section>
        <section id="abstract">
          <h2>Abstract</h2>
        </section>
