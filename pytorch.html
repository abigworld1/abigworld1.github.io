<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>【PyTorchで学ぶ深層学習】走る作曲家のAIカフェ</title>
    <link rel="stylesheet" href="style.css"> 
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1050827580219099"
     crossorigin="anonymous"></script>
</head>
<body>
    <header>
        <h1>走る作曲家のAIカフェ</h1>
        <nav>
            <ul>
                <li><a href="index.html">ホーム</a></li>
                <li><a href="study.html">勉強</a></li>
                <li><a href="music.html">音楽</a></li>
                <li><a href="sports.html">スポーツ</a></li>
            </ul>
        </nav>
    </header>
    <main>
        <section>
            <h2>目次</h2>
            <ul>
                <li><a href="#overview">Overview</a></li>
                <li><a href="#source">Source</a></li>
                <li><a href="#python">ディープラーニングのためのPython</a></li>
                <li><a href="#pytorch">PyTorchの基本</a></li>
            </ul>
        </section>
        <section id="overview">
            <h2>Overview</h2>
            深層学習とは、人工ニューラルネットワークを多層に積み重ねて学習させる手法で、複雑なデータのパターンや特徴を自動的に抽出することができる機械学習の一分野です。<br>
            このページでは、深層学習のライブラリであるPyTorchを用いて、深層学習の基礎を学んでいきます。
        </section>
        <section id="source">
            <h2>Source</h2>
            <p>以下の講義・書籍を参考にしました。</p>
            <ul>
                <li><a href="https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI">MIT 6.S191: Introduction to Deep Learning</a></li>
                <li><a href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">Quickstart — PyTorch Tutorials 2.4.0+cu121 documentation</a></li>
                <li><a href="https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/af0caf6d7af0dda755f4c9d7af9ccc2c/quickstart_tutorial.ipynb">quickstart_tutorial.ipynb</a></li>
                <li><a href="https://yutaroogawa.github.io/pytorch_tutorials_jp/">PyTorchチュートリアル（日本語翻訳版）</a></li>
                <li><a href="https://github.com/makaishi2/pytorch_book_info">makaishi2_pytorch_book_info_ 書籍「最短コースでわかるPyTorch深層学習プログラミング」用サポートサイト</a></li>
                <li><a href="https://www.amazon.co.jp/%E6%9C%80%E7%9F%AD%E3%82%B3%E3%83%BC%E3%82%B9%E3%81%A7%E3%82%8F%E3%81%8B%E3%82%8B-PyTorch-%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0-%E8%B5%A4%E7%9F%B3-%E9%9B%85%E5%85%B8/dp/4296110322#customerReviews">最短コースでわかる PyTorch &深層学習プログラミング</a></li>
            </ul>     
        </section>
        <section id="python">
            <h2>ディープラーニングのためのPython</h2>
            <h3>コンテナデータ型</h3>
            <p>コンテナデータ型：「リスト」やNumPy配列のように、名前から実際のデータにアクセスするのにインデックスを経由する必要があるデータの型。</p>
            <p>
                <pre><code>
x = np.array([5, 7, 9])
y = x
x[1] = -1
print(y)
                </code></pre>
            この出力は、<code2>[5, -1, 9]</code2>となる。xの要素の変更がyに影響しないようにするには、<code2>y = x.copy()</code2>を使う。</p>
            <p>PyTorchで扱うデータは「テンソル」(Tensor)というクラスのインスタンスに保存される。</p>
            <p>テンソルの場合も同様にcopyしておけば他からの影響を気にしないで済む。</p>
            <h3>カスタムクラス定義</h3>
            <b>オブジェクト指向の基礎概念</b>
            <p>クラス：「型」。</p>
            <p>インスタンス：「型」から生成された個別の実体。</p>
            <p>クラスは、「属性」と呼ばれるクラス内の変数を持っている。</p>
            <p>「関数」あるいは「メソッド」と呼ばれる処理機能も持っている。</p>
            <p>属性と呼ばれるクラス内の変数の値は、インスタンスごとに異なる。</p>
            <b>最初のクラス定義</b>
            <p>例）Pointというクラスを定義してみる。</p>
            <p>Pointクラスの属性のxとyは、点のx座標とy座標である。</p>
            <p>また、関数drawは、自分を点としてグラフに表示する関数である。</p>
            <p>以下のように実装される。</p>
            <pre><code>
import matplotlib.pyplot as plt

# 円描画に必要なライブラリ
import matplotlib.patches as patches

# クラスPointの定義
Class Point:
    # インスタンス生成時にxとyの２つの引数を持つ
    def __init__(self, x, y):
        # インスタンスの属性xに第１引数をセットする
        self.x = x
        # インスタンスの属性yに第２引数をセットする
        self.y = y
    # 描画関数drawの定義（引数なし）
        def draw(self):
            # (x, y)に点を描画する
            plt.plot(self.x, self.y, marker='o', markersize=10, c='k')
            </code></pre>
            <p><code2>__init__</code2>は初期化処理。</p>
            <p><code2>self</code2>はクラスからインスタンスが生成された際、インスタンス自身を指す。</p>
            <b>最初のインスタンス生成</b>
            <pre><code>
# クラスPointからインスタンス変数p1とp2を生成する
p1 = Point(2, 3)
p2 = Point(-1, -2)
            </code></pre>
            <p>引数リストの引数は、__init__関数の定義の引数からselfを取り除いたもの。</p>
            <b>インスタンス属性へのアクセス</b>
            <pre><code>
# p1とp2の属性x、yの参照
print(p1.x, p1.y)
print(p2.x, p2.y)
            </code></pre>
            <b>draw関数の呼び出し</b>
            <pre><code>
# p1とp2のdraw関数を呼び出し、2つの点を描画する
p1.draw()
p2.draw()
plt.xlim(-4, 4)
plt.ylim(-4, 4)
plt.show()
            </code></pre>
            <b>Circleクラスの定義</b>
            <p>中心点のx座標とy座標の他に半径を意味する属性rを持つ。</p>
            <p>xとyについてはPointクラスの定義を再利用できる（「クラスの継承」）。</p>
            <pre><code>
# Pointの子クラスCircleの定義
class Circle(Point)
    # Circleはインスタンス生成時に引数x、y、rを持つ
    def __init__(self, x, y, r):
        # xとyは、親クラスの属性として設定
        super().__init__(x, y)
        # rは、Circleの属性として設定
        self.r = r

    # Circleのdraw関数は、親の関数呼び出しのあとで、円の描画も独自に行う
    def draw(self):
        # 親クラスのdraw関数呼び出し
        super().draw()
                
        # 円の描画
        c = patches.Circle(xy=(self.x, self.y), radius=self.r, fc='b', ec='k')
        ax.add_patch(c)
            </code></pre>
            <p>CircleクラスはPointクラスの子クラスとして定義している。</p>
            <b>Circleインスタンスの生成とdraw関数の呼び出し</b>
            <pre><code>
# クラスCircleからインスタンス変数c1を生成する
c1 = Circle(1, 0, 2)

# p1, p2, c1のそれぞれのdraw関数を呼び出す
ax = plt.subplot()
p1.draw()
p2.draw()
c1.draw()
plt.xlim(-4, 4)
plt.ylim(-4, 4)
plt.show()
            </code></pre>
            <p>親クラスと同じ名前の関数を子クラスでも定義して振る舞いを変更させることを「オーバーライド」と呼ぶ。</p>
            <h3>インスタンスを関数として扱う</h3>
            <p>クラスから生成したインスタンスを呼び出し可能な関数にする。</p>
            <pre><code>
# 関数クラスHの定義
class H:
    def __call__(self, x):
        return 2*x**2 + 2
            </code></pre>
            <pre><code>
# hが関数として動作することを確認する

# NumPy配列としてxを定義
x = np.arange(-2, 2.1, 0.25)
print(x)

# Hクラスのインスタンスとしてhを生成
h = H()

# 関数hの呼び出し
y = h(x)
print(y)
            </code></pre>
        </section>
        <section id="pytorch">
            <h2>PyTorchの基本</h2>
            <h3>重要な概念</h3>
            <p>PyTorchでは、テンソルという独自のクラスでデータを表現する。</p>
            <p>PyTorchの最大の特徴は、自動微分機能。</p>
            <h3>テンソル</h3>
            <b>ライブラリインポート</b>
            <pre><code>
import torch
            </code></pre>
            <b>色々な階層のテンソル</b>
            <pre><code>
# 0階テンソル（スカラー）
r0 = torch.tensor(1.0).float()
            </code></pre>
            <p>テンソル変数を作るのに一番簡単なのは、torch.tensor関数を使う方法。</p>
            <p>テンソル変数の生成時には、必ず後ろにfloat関数の呼び出しをつけて、dtype（テンソル変数の要素のデータ型）を強制的にfloat32に変換する。</p>
            <pre><code>
# 1階テンソル（ベクトル）

# 1階のNumPy変数作成
r1_np = np.array([1, 2, 3, 4, 5])

# NumPyからテンソルに変換
r1 = torch.tensor(r1_np).float()

# dtypeを調べる
print(r1.dtype)

# shapeを調べる
print(r1.shape)

# データを調べる
print(r1.data)
            </code></pre>
            <pre><code>
# 2階テンソル（行列）

# 2階のNumPy変数作成
r2_np = np.array([1, 5, 6], [4, 3, 2])

# NumPyからテンソルに変換
r2 = torch.tensor(r2_np).float()
            </code></pre>
            <pre><code>
# 3階テンソル

# 乱数seedの初期化
torch.manual_seed(123)

# shape=[3,2,2]の正規分布変数テンソルを作る
r3 = torch.randn((3, 2, 2))
            </code></pre>
            <b>整数値のテンソル</b>
            <p>PyTorchによる計算では、そのほとんどの場合、数値型としてdtype=float32を利用する。</p>
            <p>しかし、「多値分類」用の損失関数である、nn.CrossEntropyLossとnn.NLLLossは、損失関数呼び出し時に、第2引数に整数型を指定する必要がある。</p>
            <p>その際は、以下のように整数型へ変換する。</p>
            <pre><code>
r5 = r1.long()
            </code></pre>
            <p>このようにlong関数をかけると、dtype=torch.int64になる。</p>
            <b>view関数</b>
            <p>view関数は、NumPyのreshape関数に相当し、変数の階数を変換することができる。</p>
            <pre><code>
# 2階化（r3は[3,2,2]の3階テンソル）
# 要素数に-1を指定すると、この数を自動調整する
r6 = r3.view(3, -1)
            </code></pre>
            <p>結果として、[3, 4]の2階テンソルが得られる。</p>
            <pre><code>
# 1階化
r7 - r3.view(-1)
            </code></pre>
            <b>それ以外の属性</b>
            <p>テンソルはデータとして扱うことも、クラスとして扱うこともできる。</p>
            <pre><code>
# requires_grad属性
print('requires_grad: ', r1.requires_grad)

# device属性
print('device: ', r1.device)
            </code></pre>
            <b>item関数</b>
            <p>スカラー（0階テンソル）に対しては、テンソルからPython本来のクラスの数値（floatまたはint）を取り出すのにitem関数が使える。</p>
            <p>計算結果テンソルとしてのlossから、データ記録用に値だけを抽出する場合によく用いる。</p>
            <pre><code>
item = r0.item()
            </code></pre>
            <p>この関数は、1階以上のテンソルを対象にできない。</p>
            <b>max関数</b>
            <pre><code>
# max関数を引数無しで呼び出すと、全体の最大値が取得できる
print(r2.max())
            </code></pre>
            <pre><code>
# torch.max関数
# 2つ目の引数はどの軸で集約するかを意味する（軸=1: 行方向、軸=0: 列方向）
print(torch.max(r2, 1))
            </code></pre>
            <p>この呼び出し方をした場合、最大値の値そのものだけでなく、どのindexで最大値を取ったかも返ってくる。</p>
            <p>後ろに[1]をつけると、後者のみを抽出できる。</p>
            <pre><code>
# 何番目の要素が最大値を取るかは、indicesを調べると良い
# 以下の計算は、多値分類で予測ラベルを求めるときによく利用される
print(torch.max(r2, 1)[1])
            </code></pre>
            <p>「複数の予測器の出力のうち、最も大きな値を出した予測器のindexが予測結果ラベルになる」ことを実装している。</p>
            <b>NumPy変数への変換</b>
            <pre><code>
# NumPy化
r2_np = r2.data.numpy()
            </code></pre>
            <p>ただし、この方法だと、テンソル変数とNumPy配列は同じデータを指すため、テンソル側で値を変えるとNumPyも連動して値が変わる。</p>
            <p>連動しないようにするには、r2.data.numpy.copy()として、データのコピーを作る。</p>
            <h3>自動微分機能</h3>
        </section>
    </main>
</body>
</html>
